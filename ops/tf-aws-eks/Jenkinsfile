pipeline{
    agent any
    environment {
        // AWS Credentials
        AWS_ACCESS_KEY_ID = credentials('AWS_ACCESS_KEY_ID')
        AWS_SECRET_ACCESS_KEY = credentials('AWS_SECRET_ACCESS_KEY')
        AWS_DEFAULT_REGION = "us-east-1"
        
        // EKS Configuration
        CLUSTER_NAME = "EKS-Cluster-ballandbeer"
        IAM_USER_NAME = "hhh_user"
        
        // Repository Configuration
        REPO_URL = "https://github.com/haihhdev/ballandbeer.git"
        BRANCH_NAME = "master"
        GITHUB_TOKEN = credentials('GITHUB_TOKEN')
        
        // Terraform Configuration
        TERRAFORM_DIR = "ops/tf-aws-eks"
        TF_VARS_FILE = "variables/dev.tfvars"
        
        // Monitoring Configuration
        MONITORING_NAMESPACE = "monitoring"
        PROMETHEUS_PORT = "9090"
        GRAFANA_DASHBOARDS_DIR = "ops/monitoring/grafana/dashboards"
        GRAFANA_VALUES_FILE = "ops/monitoring/grafana/values.yaml"
    }
    stages {
        stage('Checkout SCM') {
            steps {
                script {
                    checkout scmGit(branches: [[name: "*/${BRANCH_NAME}"]], extensions: [], userRemoteConfigs: [[url: "${REPO_URL}"]])
                }
            }
        }
        stage('Initializing Terraform'){
            steps {
                script {
                    dir("${TERRAFORM_DIR}"){
                        sh 'terraform init'
                    }
                }
            }
        }
        
        stage('Terraform Validate & Plan'){
            steps {
                script {
                    dir("${TERRAFORM_DIR}"){
                        sh 'terraform validate'
                        sh "terraform plan -var-file=${TF_VARS_FILE}"
                    }
                }
            }
        }
        stage('Creating/Destroying EKS Cluster'){
            steps {
                script {
                    dir("${TERRAFORM_DIR}"){
                        sh "terraform $action -var-file=${TF_VARS_FILE} -auto-approve" 
                    }
                }
            }
        }
        stage('Add EKS IAM Access Entry') {
            steps {
                script {
                    sh """
                        ACCOUNT_ID=\$(aws sts get-caller-identity --query Account --output text)
                        PRINCIPAL_ARN="arn:aws:iam::\${ACCOUNT_ID}:user/${IAM_USER_NAME}"
                        CLUSTER_NAME=\$(terraform -chdir=${TERRAFORM_DIR} output -raw cluster_name)
                        
                        echo "Checking if access entry for \$PRINCIPAL_ARN exists..."
                        
                        EXISTS=\$(aws eks list-access-entries --cluster-name "\$CLUSTER_NAME" --output text | grep "\$PRINCIPAL_ARN" || true)
                        
                        if [ -n "\$EXISTS" ]; then
                            echo "Access entry for \$PRINCIPAL_ARN already exists. Skipping creation."
                        else
                            echo "Creating access entry for \$PRINCIPAL_ARN on \$CLUSTER_NAME..."
                        
                            aws eks create-access-entry \
                              --cluster-name "\$CLUSTER_NAME" \
                              --principal-arn "\$PRINCIPAL_ARN" \
                              --type STANDARD
                        
                            aws eks associate-access-policy \
                              --cluster-name "\$CLUSTER_NAME" \
                              --principal-arn "\$PRINCIPAL_ARN" \
                              --policy-arn arn:aws:eks::aws:cluster-access-policy/AmazonEKSClusterAdminPolicy \
                              --access-scope type=cluster
                        fi
                    """
                }
            }
        }
        stage('Create Grafana Dashboards ConfigMap') {
            steps {
                script {
                    sh """
                        aws eks update-kubeconfig --name ${CLUSTER_NAME}
                        kubectl create namespace ${MONITORING_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -
                        if kubectl get configmap grafana-dashboards -n ${MONITORING_NAMESPACE} > /dev/null 2>&1; then
                        echo "Grafana dashboards ConfigMap already exists, skipping..."
                        else
                        kubectl create configmap grafana-dashboards \
                            --from-file=${GRAFANA_DASHBOARDS_DIR} \
                            -n ${MONITORING_NAMESPACE}
                        fi
                    """
                }
            }
        }

        stage('Install Prometheus & Grafana') {
            steps {
                script {
                    sh """
                        aws eks update-kubeconfig --name ${CLUSTER_NAME}
                        kubectl create namespace ${MONITORING_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -
                        
                        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
                        helm repo add grafana https://grafana.github.io/helm-charts || true
                        helm repo update

                        if helm list -n ${MONITORING_NAMESPACE} | grep -q prometheus; then
                        echo "Prometheus already installed. Upgrading..."
                        else
                        echo "Installing Prometheus..."
                        fi
                        helm upgrade --install prometheus prometheus-community/prometheus \
                        --namespace ${MONITORING_NAMESPACE} \
                        --set server.persistentVolume.enabled=false

                        if helm list -n ${MONITORING_NAMESPACE} | grep -q grafana; then
                        echo "Grafana already installed. Upgrading..."
                        else
                        echo "Installing Grafana..."
                        fi
                        helm upgrade --install grafana grafana/grafana \
                        --namespace ${MONITORING_NAMESPACE} \
                        -f ${GRAFANA_VALUES_FILE}
                    """
                }
            }
        }

        stage('Port Forward Prometheus') {
            steps {
                script {
                    sh """
                        if lsof -i :${PROMETHEUS_PORT} | grep -q kubectl; then
                        echo "Port-forward to Prometheus is already running"
                        else
                        echo "Starting port-forward to Prometheus..."
                        nohup kubectl port-forward -n ${MONITORING_NAMESPACE} svc/prometheus-server ${PROMETHEUS_PORT}:80 > /dev/null 2>&1 &
                        fi
                    """
                }
            }
        }

        stage('Install ELK Stack') {
            steps {
                script {
                    sh """
                        aws eks update-kubeconfig --name ${CLUSTER_NAME}

                        echo "[+] Ensuring logging namespace exists..."
                        kubectl get ns logging >/dev/null 2>&1 || kubectl create namespace logging

                        echo "[+] Adding required Helm repos..."
                        helm repo add elastic https://helm.elastic.co || true
                        helm repo add fluent https://fluent.github.io/helm-charts || true
                        helm repo update

                        echo "[+] Installing or upgrading Elasticsearch..."
                        if helm list -n logging | grep -q elasticsearch; then
                            echo "Elasticsearch already installed. Skipping install."
                        else
                            helm upgrade --install elasticsearch elastic/elasticsearch \\
                                --namespace logging \\
                                --set replicas=1 \\
                                --set minimumMasterNodes=1 \\
                                --set volumeClaimTemplate.resources.requests.storage=10Gi
                        fi

                        echo "[+] Waiting for Elasticsearch to become ready..."
                        kubectl rollout status statefulset/elasticsearch-master -n logging --timeout=180s || {
                            echo "Elasticsearch not ready in time. Exiting..."; exit 1;
                        }

                        echo "[+] Installing or upgrading Kibana..."
                        if helm list -n logging | grep -q kibana; then
                            echo "Kibana already installed. Skipping install."
                        else
                            helm upgrade --install kibana elastic/kibana \\
                                --namespace logging \\
                                --set service.type=LoadBalancer \\
                                --set env.ELASTICSEARCH_HOSTS=http://elasticsearch-master:9200
                        fi

                        echo "[+] Installing or upgrading Fluent Bit..."
                        if helm list -n logging | grep -q fluent-bit; then
                            echo "Fluent Bit already installed. Skipping install."
                        else
                            helm upgrade --install fluent-bit fluent/fluent-bit \\
                                --namespace logging \\
                                --set backend.type=es \\
                                --set backend.es.host=elasticsearch-master.logging.svc.cluster.local \\
                                --set backend.es.port=9200
                        fi
                    """
                }
            }
        }

        stage('Install ArgoCD') {
            steps {
                script {
                    sh '''
                        kubectl create namespace argocd || true
                        kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
                        kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}' || true
                        for i in {1..30}; do
                        kubectl get secret argocd-initial-admin-secret -n argocd >/dev/null 2>&1 && break
                        echo "Waiting for admin secret... ($i)"
                        sleep 5
                        done
                        kubectl -n argocd patch secret argocd-secret \
                          -p '{"stringData": {"admin.password": "$2a$10$7EqJtq98hPqEX7fNZaFWoO5.CrQoqeluvqH7rS2WLsYl6Jx04J86e", "admin.passwordMtime": "'$(date +%FT%T%Z)'"}}'
                        kubectl -n argocd delete pod -l app.kubernetes.io/name=argocd-server
                    '''
                }
            }
        }

        stage('Deploy ArgoCD Applications') {
            steps {
                script {
                    def apps = [
                        'authen',
                        'booking',
                        'order',
                        'product',
                        'profile',
                        'frontend'
                    ]

                    for (svc in apps) {
                        def appFile = "ops/k8s/${svc}/overlays/dev/argocd-app.yaml"
                        echo "Applying ArgoCD app for: ${svc}"
                        sh "kubectl apply -f ${appFile} -n argocd"
                    }
                }
            }
        }

        stage('Add GitHub Webhook') {
            steps {
                script {
                    def webhookUrl = "http://your-jenkins-url/github-webhook/"
                    sh """
                        curl -X POST \
                        -H "Authorization: token ${GITHUB_TOKEN}" \
                        -H "Accept: application/vnd.github.v3+json" \
                        https://api.github.com/repos/haihhdev/ballandbeer/hooks \
                        -d '{
                        "name": "web",
                        "active": true,
                        "events": ["push", "pull_request"],
                        "config": {
                            "url": "${webhookUrl}",
                            "content_type": "json",
                            "insecure_ssl": "0"
                        }
                        }'
                    """
                }
            }
        }

        stage('Seed Vault Secrets') {
            steps {
                script {
                sh '''
                    kubectl exec vault -- sh -c '
                    export VAULT_ADDR=http://127.0.0.1:8200 &&
                    export VAULT_TOKEN=root &&
                    vault kv put secret/order-service \
                        KAFKA_BROKER= \
                        MONGO_URI="" \
                        PORT= \
                        JWT_SECRET=
                    '
                '''
                }
            }
            }
    }
}