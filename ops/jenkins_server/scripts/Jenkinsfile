pipeline{
    agent any
    environment {
        // AWS Credentials
        AWS_ACCESS_KEY_ID = credentials('AWS_ACCESS_KEY_ID')
        AWS_SECRET_ACCESS_KEY = credentials('AWS_SECRET_ACCESS_KEY')
        AWS_DEFAULT_REGION = "us-east-1"
        
        // EKS Configuration
        CLUSTER_NAME = "EKS-Cluster-ballandbeer"
        
        // Repository Configuration
        REPO_URL = "https://github.com/haihhdev/ballandbeer.git"
        BRANCH_NAME = "master"
        GITHUB_TOKEN = credentials('GITHUB_TOKEN')
        
        // Terraform Configuration
        TERRAFORM_DIR = "ops/tf-aws-eks"
        TF_VARS_FILE = "variables/dev.tfvars"
        
        // Monitoring Configuration
        MONITORING_NAMESPACE = "monitoring"
        KUBE_PROM_VALUES_FILE = "ops/monitoring/kube-prometheus-stack-values.yaml"
        
        // ArgoCD Configuration
        ARGOCD_NAMESPACE = "argocd"
        ARGOCD_VALUES_FILE = "ops/argocd/argocd-values.yaml"
    }
    stages {
        stage('Checkout SCM') {
            steps {
                script {
                    checkout scmGit(branches: [[name: "*/${BRANCH_NAME}"]], extensions: [], userRemoteConfigs: [[url: "${REPO_URL}"]])
                }
            }
        }
        stage('Cleanup LoadBalancers') {
            when {
                expression { return params.action == 'destroy' }
            }
            steps {
                script {
                    sh """
                        echo "Cleaning up LoadBalancer services before cluster destroy..."
                        
                        # Update kubeconfig
                        CLUSTER_NAME=\$(terraform -chdir=${TERRAFORM_DIR} output -raw cluster_name 2>/dev/null || echo "${CLUSTER_NAME}")
                        aws eks update-kubeconfig --name "\$CLUSTER_NAME" --region ${AWS_DEFAULT_REGION} || true
                        
                        # Delete LoadBalancer services to trigger AWS ELB cleanup
                        kubectl delete svc argocd-server -n argocd --ignore-not-found=true || true
                        kubectl delete svc redpanda-console -n redpanda --ignore-not-found=true || true
                        kubectl delete svc ingress-nginx-controller -n ingress-nginx --ignore-not-found=true || true
                        
                        # Wait for LoadBalancers to be deleted (max 2 minutes)
                        echo "Waiting for LoadBalancers to be cleaned up..."
                        sleep 30
                        
                        # Uninstall Helm releases to ensure clean deletion
                        helm uninstall cluster-autoscaler -n kube-system || true
                        helm uninstall argocd -n argocd || true
                        helm uninstall redpanda -n redpanda || true
                        helm uninstall kube-prometheus-stack -n monitoring || true
                        
                        echo "LoadBalancer cleanup completed"
                    """
                }
            }
        }
        
        stage('Creating/Destroying EKS Cluster'){
            steps {
                script {
                    dir("${TERRAFORM_DIR}"){
                        sh 'terraform init'
                        sh 'terraform validate'
                        sh "terraform plan -var-file=${TF_VARS_FILE}"
                        sh "terraform $action -var-file=${TF_VARS_FILE} -auto-approve" 
                    }
                }
            }
        }

        stage('Install kube-prometheus-stack') {
            steps {
                script {
                    sh """
                        aws eks update-kubeconfig --name ${CLUSTER_NAME}
                        kubectl create namespace ${MONITORING_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -
                        
                        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts || true
                        helm repo update
                        
                        if helm list -n ${MONITORING_NAMESPACE} | grep -q kube-prometheus-stack; then
                            echo "kube-prometheus-stack already installed. Upgrading..."
                            helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack \
                                --namespace ${MONITORING_NAMESPACE} \
                                -f ops/monitoring/kube-prometheus-stack-values.yaml
                        else
                            echo "Installing kube-prometheus-stack..."
                            helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
                                --namespace ${MONITORING_NAMESPACE} \
                                -f ops/monitoring/kube-prometheus-stack-values.yaml
                        fi
                        
                        echo "Waiting for Grafana to be ready..."
                        kubectl wait --for=condition=ready pod -l "app.kubernetes.io/name=grafana" \
                            -n ${MONITORING_NAMESPACE} --timeout=120s
                    """
                }
            }
        }

        stage('Install Infrastructure Prerequisites') {
            steps {
                script {
                    sh '''
                        echo "Installing AWS EBS CSI Driver..."
                        kubectl apply -k "github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/ecr/?ref=release-1.30"
                        
                        echo "Installing NGINX Ingress Controller..."
                        kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.10.1/deploy/static/provider/aws/deploy.yaml
                        
                        echo "Waiting for Ingress Controller to be ready..."
                        kubectl wait --namespace ingress-nginx \
                            --for=condition=ready pod \
                            --selector=app.kubernetes.io/component=controller \
                            --timeout=120s || true
                    '''
                }
            }
        }

        stage('Install Cluster Autoscaler') {
            steps {
                script {
                    sh """
                        echo "Getting Cluster Autoscaler IAM Role ARN from Terraform..."
                        CA_ROLE_ARN=\$(terraform -chdir=${TERRAFORM_DIR} output -raw cluster_autoscaler_role_arn)
                        echo "Cluster Autoscaler IAM Role ARN: \${CA_ROLE_ARN}"
                        
                        echo "Installing Cluster Autoscaler..."
                        helm repo add autoscaler https://kubernetes.github.io/autoscaler || true
                        helm repo update
                        
                        if helm list -n kube-system | grep -q cluster-autoscaler; then
                            echo "Cluster Autoscaler already installed. Upgrading..."
                            helm upgrade cluster-autoscaler autoscaler/cluster-autoscaler \
                                --namespace kube-system \
                                -f ops/k8s/infra/cluster-autoscaler-values.yaml \
                                --set rbac.serviceAccount.annotations."eks\\.amazonaws\\.com/role-arn"="\${CA_ROLE_ARN}"
                        else
                            echo "Installing Cluster Autoscaler..."
                            helm install cluster-autoscaler autoscaler/cluster-autoscaler \
                                --namespace kube-system \
                                -f ops/k8s/infra/cluster-autoscaler-values.yaml \
                                --set rbac.serviceAccount.annotations."eks\\.amazonaws\\.com/role-arn"="\${CA_ROLE_ARN}"
                        fi
                        
                        echo "Waiting for Cluster Autoscaler to be ready..."
                        kubectl wait --for=condition=ready pod -l "app.kubernetes.io/name=aws-cluster-autoscaler" \
                            -n kube-system --timeout=120s || true
                    """
                }
            }
        }

        stage('Install Metrics Server') {
            steps {
                script {
                    sh '''
                        echo "Installing Metrics Server for HPA support..."
                        kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
                        
                        echo "Waiting for Metrics Server to be ready..."
                        kubectl wait --for=condition=ready pod -l "k8s-app=metrics-server" \
                            -n kube-system --timeout=120s || true
                    '''
                }
            }
        }

        stage('Install ArgoCD') {
            steps {
                script {
                    sh """
                        kubectl create namespace ${ARGOCD_NAMESPACE} --dry-run=client -o yaml | kubectl apply -f -
                        
                        helm repo add argo https://argoproj.github.io/argo-helm || true
                        helm repo update
                        
                        if helm list -n ${ARGOCD_NAMESPACE} | grep -q argocd; then
                            echo "ArgoCD already installed. Upgrading..."
                            helm upgrade argocd argo/argo-cd \
                                --namespace ${ARGOCD_NAMESPACE} \
                                -f ${ARGOCD_VALUES_FILE}
                        else
                            echo "Installing ArgoCD..."
                            helm install argocd argo/argo-cd \
                                --namespace ${ARGOCD_NAMESPACE} \
                                -f ${ARGOCD_VALUES_FILE}
                        fi
                        
                        echo "Waiting for ArgoCD server to be ready..."
                        kubectl wait --for=condition=ready pod -l "app.kubernetes.io/name=argocd-server" \
                            -n ${ARGOCD_NAMESPACE} --timeout=120s
                    """
                }
            }
        }

        stage('Install Redpanda & Console') {
            steps {
                script {
                    sh """
                        aws eks update-kubeconfig --name ${CLUSTER_NAME}
                        kubectl create namespace redpanda --dry-run=client -o yaml | kubectl apply -f -
                        helm repo add redpanda https://charts.redpanda.com || true
                        helm repo update
                        helm upgrade --install redpanda redpanda/redpanda \
                            --namespace redpanda \
                            --set statefulset.replicas=1 \
                            --set console.enabled=true \
                            --set console.service.type=LoadBalancer \
                            --set tls.enabled=false \
                            --set 'console.config.kafka.adminApi.brokers[0]=http://redpanda.redpanda.svc.cluster.local:9644'
                    """
                }
            }
        }

        stage('Deploy ArgoCD Applications') {
            steps {
                script {
                    def apps = [
                        'authen',
                        'booking',
                        'order',
                        'product',
                        'profile',
                        'frontend',
                        'recommender',
                        'infra'
                    ]

                    for (svc in apps) {
                        def appFile = "ops/k8s/${svc}/overlays/dev/argocd-app.yaml"
                        echo "Applying ArgoCD app for: ${svc}"
                        try {
                            sh "kubectl apply -f ${appFile} -n argocd"
                            echo "Successfully deployed ${svc} application"
                        } catch (Exception e) {
                            echo "Failed to deploy ${svc} application: ${e.message}"
                            currentBuild.result = 'UNSTABLE'
                        }
                    }

                    sh "kubectl apply -f ops/k8s/recommender/cronjob-update-csv.yaml -n ballandbeer"
                }
            }
        }

        stage('Add GitHub Webhook') {
            steps {
                script {
                    def webhookUrl = "http://jenkins_url/github-webhook/"
                    sh """
                        curl -X POST \
                        -H "Authorization: token ${GITHUB_TOKEN}" \
                        -H "Accept: application/vnd.github.v3+json" \
                        https://api.github.com/repos/haihhdev/ballandbeer/hooks \
                        -d '{
                        "name": "web",
                        "active": true,
                        "events": ["push", "pull_request"],
                        "config": {
                            "url": "${webhookUrl}",
                            "content_type": "json",
                            "insecure_ssl": "0"
                        }
                        }'
                    """
                }
            }
        }

        stage('Show LoadBalancer URLs') {
            steps {
                script {
                    sh '''
                        kubectl apply -f ops/k8s/ingress.yaml -n ballandbeer
                        kubectl exec -it redpanda-0 -n redpanda -- rpk topic create order-topic

                        echo "\n=========================================="
                        echo "GRAFANA ACCESS"
                        echo "=========================================="
                        echo "Getting Grafana admin password..."
                        GRAFANA_PASSWORD=$(kubectl get secret kube-prometheus-stack-grafana \
                            -n monitoring -o jsonpath="{.data.admin-password}" | base64 -d)
                        echo "Grafana Admin Password: $GRAFANA_PASSWORD"
                        echo "Access Grafana: kubectl port-forward svc/kube-prometheus-stack-grafana -n monitoring 3000:80"
                        echo "Then open: http://localhost:3000"
                        
                        echo "\n=========================================="
                        echo "ARGOCD ACCESS"
                        echo "=========================================="
                        echo "Getting ArgoCD admin password..."
                        ARGOCD_PASSWORD=$(kubectl get secret -n argocd argocd-initial-admin-secret \
                            -o jsonpath="{.data.password}" | base64 -d)
                        echo "ArgoCD Admin Password: $ARGOCD_PASSWORD"
                        echo "Getting ArgoCD LoadBalancer URL..."
                        ARGOCD_URL=$(kubectl get svc argocd-server -n argocd \
                            -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
                        echo "ArgoCD URL: http://$ARGOCD_URL"
                        
                        echo "\n=========================================="
                        echo "INGRESS NGINX LOADBALANCER URL"
                        echo "=========================================="
                        kubectl get svc ingress-nginx-controller -n ingress-nginx -o 'jsonpath={.status.loadBalancer.ingress[0].hostname}'

                        echo "\n=========================================="
                        echo "REDPANDA CONSOLE LOADBALANCER URL"
                        echo "=========================================="
                        kubectl get svc redpanda-console -n redpanda -o 'jsonpath={.status.loadBalancer.ingress[0].hostname}'
                        echo ""

                    '''
                }
            }
        }
    }
}